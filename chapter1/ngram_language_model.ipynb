{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a565981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 19.0 MB/s eta 0:00:00\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "     ------------------------------------- 307.0/307.0 kB 18.5 MB/s eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.4/78.4 kB ? eta 0:00:00\n",
      "Collecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "     ---------------------------------------- 96.6/96.6 kB ? eta 0:00:00\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.7.25-cp38-cp38-win_amd64.whl (262 kB)\n",
      "     ------------------------------------- 262.8/262.8 kB 16.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in d:\\study\\notebookprojects\\hello-transformer\\venv\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.3 joblib-1.1.0 nltk-3.7 regex-2022.7.25 tqdm-4.64.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a5ef0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed2201b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''She sells sea-shells by the sea-shore. The shells she sells are sea-shells, I'm sure. For if she sells sea-shells by the sea-shore then I'm sure she sells sea-shore shells.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb68b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = text.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "093f2603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['She sells sea-shells by the sea-shore',\n",
       " \" The shells she sells are sea-shells, I'm sure\",\n",
       " \" For if she sells sea-shells by the sea-shore then I'm sure she sells sea-shore shells\",\n",
       " '']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9e5eb4",
   "metadata": {},
   "source": [
    "STEP1. 소문자 치환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcb96766",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(map(str.lower, sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f932144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['she sells sea-shells by the sea-shore',\n",
       " \" the shells she sells are sea-shells, i'm sure\",\n",
       " \" for if she sells sea-shells by the sea-shore then i'm sure she sells sea-shore shells\",\n",
       " '']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604102fc",
   "metadata": {},
   "source": [
    "STEP2. BOS/EOS 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cb09c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = '<s>'\n",
    "EOS = '</s>'\n",
    "n = 2\n",
    "BOSs = ' '.join([BOS]*(n-1) if n > 1 else [BOS])\n",
    "sentences = [' '.join([BOSs, s, EOS]) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c49e97db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> she sells sea-shells by the sea-shore </s>',\n",
       " \"<s>  the shells she sells are sea-shells, i'm sure </s>\",\n",
       " \"<s>  for if she sells sea-shells by the sea-shore then i'm sure she sells sea-shore shells </s>\",\n",
       " '<s>  </s>']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d778436",
   "metadata": {},
   "source": [
    "STEP3. 토큰화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b73a2a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "sentences = list(map(lambda s: s.split(), sentences))\n",
    "tokens = list(reduce(lambda a, b: a+b, sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a706702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<s>', 'she', 'sells', 'sea-shells', 'by', 'the', 'sea-shore', '</s>'],\n",
       " ['<s>',\n",
       "  'the',\n",
       "  'shells',\n",
       "  'she',\n",
       "  'sells',\n",
       "  'are',\n",
       "  'sea-shells,',\n",
       "  \"i'm\",\n",
       "  'sure',\n",
       "  '</s>'],\n",
       " ['<s>',\n",
       "  'for',\n",
       "  'if',\n",
       "  'she',\n",
       "  'sells',\n",
       "  'sea-shells',\n",
       "  'by',\n",
       "  'the',\n",
       "  'sea-shore',\n",
       "  'then',\n",
       "  \"i'm\",\n",
       "  'sure',\n",
       "  'she',\n",
       "  'sells',\n",
       "  'sea-shore',\n",
       "  'shells',\n",
       "  '</s>'],\n",
       " ['<s>', '</s>']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91607841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'she',\n",
       " 'sells',\n",
       " 'sea-shells',\n",
       " 'by',\n",
       " 'the',\n",
       " 'sea-shore',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'the',\n",
       " 'shells',\n",
       " 'she',\n",
       " 'sells',\n",
       " 'are',\n",
       " 'sea-shells,',\n",
       " \"i'm\",\n",
       " 'sure',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'for',\n",
       " 'if',\n",
       " 'she',\n",
       " 'sells',\n",
       " 'sea-shells',\n",
       " 'by',\n",
       " 'the',\n",
       " 'sea-shore',\n",
       " 'then',\n",
       " \"i'm\",\n",
       " 'sure',\n",
       " 'she',\n",
       " 'sells',\n",
       " 'sea-shore',\n",
       " 'shells',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '</s>']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053be260",
   "metadata": {},
   "source": [
    "STEP4. 한 번 출현한 단어 UNK 로 치환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43ba3194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'she',\n",
       " 'sells',\n",
       " 'sea-shells',\n",
       " 'by',\n",
       " 'the',\n",
       " 'sea-shore',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'the',\n",
       " 'shells',\n",
       " 'she',\n",
       " 'sells',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " \"i'm\",\n",
       " 'sure',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " 'she',\n",
       " 'sells',\n",
       " 'sea-shells',\n",
       " 'by',\n",
       " 'the',\n",
       " 'sea-shore',\n",
       " '<unk>',\n",
       " \"i'm\",\n",
       " 'sure',\n",
       " 'she',\n",
       " 'sells',\n",
       " 'sea-shore',\n",
       " 'shells',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '</s>']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNK = '<unk>'\n",
    "freq = nltk.FreqDist(tokens)\n",
    "tokens = [t if freq[t] > 1 else UNK for t in tokens]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cbefc3",
   "metadata": {},
   "source": [
    "STEP1 부터 STEP4 까지를 하나의 함수에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a99039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentences, n):\n",
    "    '''문장으로 구성된 리스트를 쪼개서 토큰 리스트로 만듬\n",
    "\n",
    "    Args:\n",
    "        sentences (list of str): 여러 개의 문장으로 구성된 리스트\n",
    "        n (int): N-gram 모델의 N 계수\n",
    "    Returns:\n",
    "        토큰 리스트\n",
    "    '''\n",
    "\n",
    "    BOS = '<s>'\n",
    "    EOS = '</s>'\n",
    "    UNK = '<unk>'\n",
    "\n",
    "    # STEP1: 소문자 치환하기\n",
    "    sentences = list(map(str.lower, sentences))\n",
    "\n",
    "    # STEP2: BOS, EOS 추가하기\n",
    "    BOSs = ' '.join([BOS]*(n-1) if n > 1 else [BOS])\n",
    "    sentences = [' '.join([BOSs, s, EOS]) for s in sentences]\n",
    "\n",
    "    # STEP3: 토큰화하기\n",
    "    sentences = list(map(lambda s: s.split(), sentences))\n",
    "    tokens = list(reduce(lambda a, b: a+b, sentences))\n",
    "\n",
    "    # STEP4: 한번 출현한 단어 UNK으로 치환하기\n",
    "    freq = nltk.FreqDist(tokens)\n",
    "    tokens = [t if freq[t] > 1 else UNK for t in tokens]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bddc766",
   "metadata": {},
   "source": [
    "## N-gram 개수 세기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72575789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>,she: 1\n",
      "she,sells: 4\n",
      "sells,sea-shells: 2\n",
      "sea-shells,by: 2\n",
      "by,the: 2\n",
      "the,sea-shore: 2\n",
      "sea-shore,</s>: 1\n",
      "</s>,<s>: 3\n",
      "<s>,the: 1\n",
      "the,shells: 1\n",
      "shells,she: 1\n",
      "sells,<unk>: 1\n",
      "<unk>,<unk>: 2\n",
      "<unk>,i'm: 2\n",
      "i'm,sure: 2\n",
      "sure,</s>: 1\n",
      "<s>,<unk>: 1\n",
      "<unk>,she: 1\n",
      "sea-shore,<unk>: 1\n",
      "sure,she: 1\n",
      "sells,sea-shore: 1\n",
      "sea-shore,shells: 1\n",
      "shells,</s>: 1\n",
      "<s>,</s>: 1\n"
     ]
    }
   ],
   "source": [
    "bigram = nltk.ngrams(tokens, n=2)\n",
    "vocab = nltk.FreqDist(bigram)\n",
    "for k, v in vocab.items():\n",
    "    a, b = k\n",
    "    print(f'{a},{b}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc2cf73",
   "metadata": {},
   "source": [
    "## SimpleNgramLanguageModel 언어모델 클래스 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf76ccc",
   "metadata": {},
   "source": [
    "bigram, vocab 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6999f8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x21bc3e67580>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "a = ['a', 'b', 'b', 'b', 'a', 'a', 'a', 'c']\n",
    "bigram = nltk.ngrams(a, n=2)\n",
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0292698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('b', 'b'): 2, ('a', 'a'): 2, ('a', 'b'): 1, ('b', 'a'): 1, ('a', 'c'): 1})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = nltk.FreqDist(bigram)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e871ed96",
   "metadata": {},
   "source": [
    "## 최종 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82953551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ziipp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fd350a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNgramLanguageModel():\n",
    "    def __init__(self, train_data, n):\n",
    "        sentences = nltk.tokenize.sent_tokenize(train_data)\n",
    "        sentences = train_data.split('.')\n",
    "\n",
    "        tokens = preprocess(sentences, n)\n",
    "        self.vocab = self.build_model(tokens, n)\n",
    "\n",
    "    def build_model(self, tokens, n):\n",
    "        ngrams = nltk.ngrams(tokens, n)\n",
    "        nvocab = nltk.FreqDist(ngrams)\n",
    "\n",
    "        if n == 1:\n",
    "            vocab = nltk.FreqDist(tokens)\n",
    "            vocab_size = len(nvocab)\n",
    "            return {v: c/vocab_size for v, c in vocab.items()}\n",
    "        else:\n",
    "            mgrams = nltk.ngrams(tokens, n-1)\n",
    "            mvocab = nltk.FreqDist(mgrams)\n",
    "            def ngram_prob(ngram, ncount):\n",
    "                mgram = ngram[:-1]\n",
    "                mcount = mvocab[mgram]\n",
    "                return ncount / mcount\n",
    "            return {v: ngram_prob(v, c) for v, c in nvocab.items()}\n",
    "\n",
    "    def build_vocab(self, data):\n",
    "        vocab = {}\n",
    "        for d in data:\n",
    "            for k, v in Counter(d).items():\n",
    "                try:\n",
    "                    vocab[k] += v\n",
    "                except KeyError:\n",
    "                    vocab[k] = v\n",
    "\n",
    "        return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90b7bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = SimpleNgramLanguageModel(text, n=3)\n",
    "vocab = lm.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e27c519f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('<s>', '<s>', 'she'): 0.25,\n",
       " ('<s>', 'she', 'sells'): 1.0,\n",
       " ('she', 'sells', 'sea-shells'): 0.5,\n",
       " ('sells', 'sea-shells', 'by'): 1.0,\n",
       " ('sea-shells', 'by', 'the'): 1.0,\n",
       " ('by', 'the', 'sea-shore'): 1.0,\n",
       " ('the', 'sea-shore', '</s>'): 0.5,\n",
       " ('sea-shore', '</s>', '<s>'): 1.0,\n",
       " ('</s>', '<s>', '<s>'): 1.0,\n",
       " ('<s>', '<s>', 'the'): 0.25,\n",
       " ('<s>', 'the', 'shells'): 1.0,\n",
       " ('the', 'shells', 'she'): 1.0,\n",
       " ('shells', 'she', 'sells'): 1.0,\n",
       " ('she', 'sells', '<unk>'): 0.25,\n",
       " ('sells', '<unk>', '<unk>'): 1.0,\n",
       " ('<unk>', '<unk>', \"i'm\"): 0.5,\n",
       " ('<unk>', \"i'm\", 'sure'): 1.0,\n",
       " (\"i'm\", 'sure', '</s>'): 0.5,\n",
       " ('sure', '</s>', '<s>'): 1.0,\n",
       " ('<s>', '<s>', '<unk>'): 0.25,\n",
       " ('<s>', '<unk>', '<unk>'): 1.0,\n",
       " ('<unk>', '<unk>', 'she'): 0.5,\n",
       " ('<unk>', 'she', 'sells'): 1.0,\n",
       " ('the', 'sea-shore', '<unk>'): 0.5,\n",
       " ('sea-shore', '<unk>', \"i'm\"): 1.0,\n",
       " (\"i'm\", 'sure', 'she'): 0.5,\n",
       " ('sure', 'she', 'sells'): 1.0,\n",
       " ('she', 'sells', 'sea-shore'): 0.25,\n",
       " ('sells', 'sea-shore', 'shells'): 1.0,\n",
       " ('sea-shore', 'shells', '</s>'): 1.0,\n",
       " ('shells', '</s>', '<s>'): 1.0,\n",
       " ('<s>', '<s>', '</s>'): 0.25}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2ac4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
