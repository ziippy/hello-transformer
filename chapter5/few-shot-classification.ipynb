{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45d5ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_classes, num_support_per_class,\n",
    "                 vocab_size, embed_size, hidden_size,\n",
    "                 output_dim, weights):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_support = num_classes * num_support_per_class\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        if weights is not None:\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(weights))\n",
    "\n",
    "        self.bilstm = nn.LSTM(embed_size, hidden_size, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.fc1 = nn.Linear(2 * hidden_size, output_dim)\n",
    "        self.fc2 = nn.Linear(output_dim, output_dim)\n",
    "\n",
    "    def attention(self, x):\n",
    "        weights = torch.tanh(self.fc1(x))\n",
    "        weights = self.fc2(weights)  # (batch=k*c, seq_len, d_a)\n",
    "        batch, seq_len, d_a = weights.shape\n",
    "        weights = weights.transpose(1, 2)  # (batch=k*c, d_a, seq_len)\n",
    "        weights = weights.contiguous().view(-1, seq_len)\n",
    "        weights = F.softmax(weights, dim=1).view(batch, d_a, seq_len)\n",
    "        sentence_embeddings = torch.bmm(weights, x)  # (batch=k*c, d_a, 2*hidden)\n",
    "        avg_sentence_embeddings = torch.mean(sentence_embeddings, dim=1)  # (batch, 2*hidden)\n",
    "        return avg_sentence_embeddings\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        batch_size, _ = x.shape\n",
    "        if hidden is None:\n",
    "            h = x.data.new(2, batch_size, self.hidden_size).fill_(0).float()\n",
    "            c = x.data.new(2, batch_size, self.hidden_size).fill_(0).float()\n",
    "        else:\n",
    "            h, c = hidden\n",
    "        x = self.embedding(x)\n",
    "        outputs, _ = self.bilstm(x, (h, c))  # (batch=k*c,seq_len,2*hidden)\n",
    "        outputs = self.attention(outputs)  # (batch=k*c, 2*hidden)\n",
    "        # (c*s, 2*hidden_size), (c*q, 2*hidden_size)\n",
    "        support, query = outputs[0: self.num_support], outputs[self.num_support:]\n",
    "        # print('support, query: {} {}'.format(support.shape, query.shape))\n",
    "        return support, query\n",
    "\n",
    "\n",
    "class Induction(nn.Module):\n",
    "    def __init__(self, C, S, H, iterations):\n",
    "        super(Induction, self).__init__()\n",
    "        self.C = C\n",
    "        self.S = S\n",
    "        self.H = H\n",
    "        self.iterations = iterations\n",
    "        self.W = torch.nn.Parameter(torch.randn(H, H))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b_ij = torch.zeros(self.C, self.S).to(x)\n",
    "        for _ in range(self.iterations):\n",
    "            d_i = F.softmax(b_ij.unsqueeze(2), dim=1)  # (C,S,1)\n",
    "            a = x.reshape(-1, self.H)\n",
    "            b = torch.mm(a, self.W)\n",
    "            #print('x: {}'.format(x.shape))\n",
    "            #print(a.shape, b.shape)\n",
    "            e_ij = torch.mm(x.reshape(-1, self.H), self.W).reshape(self.C, self.S, self.H)  # (C,S,H)\n",
    "            c_i = torch.sum(d_i * e_ij, dim=1)  # (C,H)\n",
    "            # squash\n",
    "            squared = torch.sum(c_i ** 2, dim=1).reshape(self.C, -1)\n",
    "            coeff = squared / (1 + squared) / torch.sqrt(squared + 1e-9)\n",
    "            c_i = coeff * c_i\n",
    "            c_produce_e = torch.bmm(e_ij, c_i.unsqueeze(2))  # (C,S,1)\n",
    "            b_ij = b_ij + c_produce_e.squeeze(2)\n",
    "\n",
    "        return c_i\n",
    "\n",
    "\n",
    "class Relation(nn.Module):\n",
    "    def __init__(self, C, H, out_size):\n",
    "        super(Relation, self).__init__()\n",
    "        self.out_size = out_size\n",
    "        self.M = torch.nn.Parameter(torch.randn(H, H, out_size))\n",
    "        self.W = torch.nn.Parameter(torch.randn(C * out_size, C))\n",
    "        self.b = torch.nn.Parameter(torch.randn(C))\n",
    "\n",
    "    def forward(self, class_vector, query_encoder):  # (C,H) (Q,H)\n",
    "        mid_pro = []\n",
    "        for slice in range(self.out_size):\n",
    "            slice_inter = torch.mm(torch.mm(class_vector, self.M[:, :, slice]), query_encoder.transpose(1, 0))  # (C,Q)\n",
    "            mid_pro.append(slice_inter)\n",
    "        mid_pro = torch.cat(mid_pro, dim=0)  # (C*out_size,Q)\n",
    "        V = F.relu(mid_pro.transpose(0, 1))  # (Q,C*out_size)\n",
    "        probs = torch.sigmoid(torch.mm(V, self.W) + self.b)  # (Q,C)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a5aebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "#from model import FewShotInduction\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "#from criterion import Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a0177d",
   "metadata": {},
   "source": [
    "### 토크나이저 변수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7efb062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반드시 do_lower_case=True로 해야 한다.\n",
    "# bert-base-uncased는 영어 데이터를 소문자로 변환해서 학습한 모델이기 때문이다.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b139fc27",
   "metadata": {},
   "source": [
    "### 데이터셋과 데이터로더 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41874a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonDataset():\n",
    "    def __init__(self, data_path, tokenizer, dtype):\n",
    "        self.data_path = data_path\n",
    "        self.tokenizer = tokenizer\n",
    "        with open(f'{dtype}.list', 'r') as f:\n",
    "            self.categories = [oneline.rstrip() for oneline in f]\n",
    "        self.support_dataset = {}\n",
    "        self.dataset = {}\n",
    "        for category in tqdm(self.categories, desc='reading categories'):\n",
    "            self.dataset[category] = {\n",
    "                'neg': self.get_data(category, 'neg', dtype),\n",
    "                'pos': self.get_data(category, 'pos', dtype)\n",
    "            }\n",
    "        \n",
    "        if dtype == 'test' or dtype == 'dev':\n",
    "            for category in tqdm(self.categories, desc='reading categories for support'):\n",
    "                self.support_dataset[category] = {\n",
    "                    'neg': self.get_data(category, 'neg', 'train'),\n",
    "                    'pos': self.get_data(category, 'pos', 'train'),\n",
    "                }\n",
    "        \n",
    "    def read_files(self, category, label, dtype):\n",
    "        data = {\n",
    "            'text': [],\n",
    "            'label': []\n",
    "        }\n",
    "        for t in ['t2', 't4', 't5']:\n",
    "            filename = f'{category}.{t}.{dtype}'\n",
    "            with open(os.path.join(self.data_path, filename), 'r', encoding='utf-8') as f:\n",
    "                for oneline in f:\n",
    "                    oneline = oneline.rstrip()\n",
    "                    text = oneline[:-2]\n",
    "                    if int(oneline[-2:]) == 1 and label == 'pos':\n",
    "                        tensor = self.tokenizer(text, return_tensors='pt')\n",
    "                        data['text'].append(tensor['input_ids'][0])\n",
    "                        data['label'].append(1)\n",
    "                    elif int(oneline[-2:]) == -1 and label == 'neg':\n",
    "                        tensor = self.tokenizer(text, return_tensors='pt')\n",
    "                        data['text'].append(tensor['input_ids'][0])\n",
    "                        data['label'].append(0)\n",
    "        data['label'] = torch.tensor(data['label'])\n",
    "        return data\n",
    "    \n",
    "    def get_data(self, category, label, dtype):\n",
    "        data = self.read_files(category, label, dtype)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32053c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Amazon_few_shot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dab1e841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading categories:   0%|                                                                       | 0/14 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
      "reading categories: 100%|██████████████████████████████████████████████████████████████| 14/14 [02:41<00:00, 11.55s/it]\n",
      "reading categories: 100%|████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  5.05it/s]\n",
      "reading categories for support: 100%|████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.54s/it]\n",
      "reading categories: 100%|████████████████████████████████████████████████████████████████| 4/4 [00:18<00:00,  4.56s/it]\n",
      "reading categories for support: 100%|████████████████████████████████████████████████████| 4/4 [00:00<00:00, 14.65it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = AmazonDataset(data_path, tokenizer, 'train')\n",
    "dev_dataset = AmazonDataset(data_path, tokenizer, 'dev')\n",
    "test_dataset = AmazonDataset(data_path, tokenizer, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac6bf606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_text(a_text, b_text):\n",
    "    a_text_len = a_text.shape[1]\n",
    "    b_text_len = b_text.shape[1]\n",
    "\n",
    "    if a_text_len > b_text_len:\n",
    "        b_text = torch.cat([b_text, torch.zeros(b_text.shape[0], a_text_len-b_text_len).long()], dim=1)\n",
    "    else:\n",
    "        a_text = torch.cat([a_text, torch.zeros(a_text.shape[0], b_text_len-a_text_len).long()], dim=1)\n",
    "        \n",
    "    return a_text, b_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2271effa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonDataLoader():\n",
    "    def __init__(self, dataset, batch_size, n_support):\n",
    "        assert n_support % 2 == 0, 'n_support should be multiple of 2'\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.n_support = n_support\n",
    "        self.neg_idx = {k:0 for k in dataset.dataset}\n",
    "        self.pos_idx = {k:0 for k in dataset.dataset}\n",
    "        self.neg_len = {k:len(dataset.dataset[k]['neg']['text']) for k in dataset.dataset}\n",
    "        self.pos_len = {k:len(dataset.dataset[k]['pos']['text']) for k in dataset.dataset}\n",
    "        self.neg = {k:dataset.dataset[k]['neg'] for k in dataset.dataset}\n",
    "        self.pos = {k:dataset.dataset[k]['pos'] for k in dataset.dataset}\n",
    "        self.idx = 0\n",
    "        self.categories = [k for k in dataset.dataset]\n",
    "        \n",
    "        # prepare for test dataset, support dataset should come from \"*.train\"\n",
    "        self.neg_support_idx = {}\n",
    "        self.pos_support_idx = {}\n",
    "        self.neg_support_len = {}\n",
    "        self.pos_support_len = {}\n",
    "        if self.dataset.support_dataset:\n",
    "            self.neg_support_idx = {k:0 for k in self.dataset.support_dataset}\n",
    "            self.pos_support_idx = {k:0 for k in self.dataset.support_dataset}\n",
    "            self.neg_support_len = {k:len(self.dataset.support_dataset[k]['neg']['text']) for k in self.dataset.support_dataset}\n",
    "            self.pos_support_len = {k:len(self.dataset.support_dataset[k]['pos']['text']) for k in self.dataset.support_dataset}\n",
    "        \n",
    "    def get_batch(self):\n",
    "        category = self.categories[self.idx % len(self.categories)]\n",
    "        neg = self.neg[category]\n",
    "        pos = self.pos[category]\n",
    "        neg_start_idx = self.neg_idx[category] % self.neg_len[category]\n",
    "        pos_start_idx = self.pos_idx[category] % self.pos_len[category]\n",
    "        \n",
    "        # prepare negative/positive dataset\n",
    "        neg_text = neg['text'][neg_start_idx:neg_start_idx+(self.batch_size//2)]\n",
    "        pos_text = pos['text'][pos_start_idx:pos_start_idx+(self.batch_size//2)]\n",
    "        neg_label = neg['label'][neg_start_idx:neg_start_idx+(self.batch_size//2)]\n",
    "        pos_label = pos['label'][pos_start_idx:pos_start_idx+(self.batch_size//2)]\n",
    "        self.neg_idx[category] += (self.batch_size//2)\n",
    "        self.pos_idx[category] += (self.batch_size//2)\n",
    "        \n",
    "        if len(neg_text) + len(pos_text) != self.batch_size:\n",
    "            return self.get_batch()\n",
    "            \n",
    "        # padding text dataset\n",
    "        neg_text = pad_sequence([n for n in neg_text], batch_first=True)\n",
    "        pos_text = pad_sequence([p for p in pos_text], batch_first=True)\n",
    "        neg_text, pos_text = pad_text(neg_text, pos_text)\n",
    "            \n",
    "        # prepare support/query text\n",
    "        neg_support_text = neg_text[:self.n_support//2]\n",
    "        pos_support_text = pos_text[:self.n_support//2]\n",
    "        neg_query_text = neg_text[self.n_support//2:]\n",
    "        pos_query_text = pos_text[self.n_support//2:]\n",
    "        \n",
    "        # prepare support/query label\n",
    "        neg_support_label = neg_label[:self.n_support//2]\n",
    "        pos_support_label = pos_label[:self.n_support//2]\n",
    "        neg_query_label = neg_label[self.n_support//2:]\n",
    "        pos_query_label = pos_label[self.n_support//2:]\n",
    "        \n",
    "        # merge support/query text\n",
    "        support_text = torch.cat([neg_support_text, pos_support_text], dim=0)\n",
    "        query_text = torch.cat([neg_query_text, pos_query_text], dim=0)\n",
    "        \n",
    "        # merge support/query label\n",
    "        support_label = torch.cat([neg_support_label, pos_support_label], dim=0)\n",
    "        query_label = torch.cat([neg_query_label, pos_query_label], dim=0)\n",
    "        \n",
    "        # make data and label\n",
    "        data = torch.cat([support_text, query_text], dim=0)\n",
    "        label = torch.cat([support_label, query_label], dim=0)\n",
    "        \n",
    "        # increase category index\n",
    "        self.idx += 1\n",
    "        return data, label\n",
    "    \n",
    "    def get_batch_test(self):\n",
    "        assert self.dataset.support_dataset, 'support_dataset is empty'\n",
    "        \n",
    "        category = self.categories[self.idx % len(self.categories)]\n",
    "        neg = self.neg[category]\n",
    "        pos = self.pos[category]\n",
    "        neg_query_start_idx = self.neg_idx[category] % self.neg_len[category]\n",
    "        pos_query_start_idx = self.pos_idx[category] % self.pos_len[category]\n",
    "        neg_support_start_idx = self.neg_support_idx[category] % self.neg_support_len[category]\n",
    "        pos_support_start_idx = self.pos_support_idx[category] % self.pos_support_len[category]\n",
    "        \n",
    "        # prepare negative/positive support dataset from support_dataset\n",
    "        category_suuport_dataset = self.dataset.support_dataset[category]\n",
    "        neg_support_text = category_suuport_dataset['neg']['text'][neg_support_start_idx:neg_support_start_idx+self.n_support//2]\n",
    "        pos_support_text = category_suuport_dataset['pos']['text'][pos_support_start_idx:pos_support_start_idx+self.n_support//2]\n",
    "        neg_support_label = category_suuport_dataset['neg']['label'][neg_support_start_idx:neg_support_start_idx+self.n_support//2]\n",
    "        pos_support_label = category_suuport_dataset['pos']['label'][pos_support_start_idx:pos_support_start_idx+self.n_support//2]\n",
    "        self.neg_support_idx[category] += (self.n_support//2)\n",
    "        self.pos_support_idx[category] += (self.n_support//2)\n",
    "        \n",
    "        # prepare negative/positive query dataset\n",
    "        neg_query_text = neg['text'][neg_query_start_idx:neg_query_start_idx+(self.batch_size//2 - self.n_support//2)]\n",
    "        pos_query_text = pos['text'][pos_query_start_idx:pos_query_start_idx+(self.batch_size//2 - self.n_support//2)]\n",
    "        neg_query_label = neg['label'][neg_query_start_idx:neg_query_start_idx+(self.batch_size//2 - self.n_support//2)]\n",
    "        pos_query_label = pos['label'][pos_query_start_idx:pos_query_start_idx+(self.batch_size//2 - self.n_support//2)]\n",
    "        self.neg_idx[category] += (self.batch_size//2 - self.n_support//2)\n",
    "        self.pos_idx[category] += (self.batch_size//2 - self.n_support//2)\n",
    "        \n",
    "        # padding support text dataset\n",
    "        if self.n_support:\n",
    "            neg_support_text = pad_sequence([n for n in neg_support_text], batch_first=True)\n",
    "            pos_support_text = pad_sequence([n for n in pos_support_text], batch_first=True)\n",
    "            neg_support_text, pos_support_text = pad_text(neg_support_text, pos_support_text)\n",
    "        else:\n",
    "            neg_support_text = torch.tensor([[]])\n",
    "            pos_support_text = torch.tensor([[]])\n",
    "            \n",
    "        # padding text dataset\n",
    "        neg_query_text = pad_sequence([n for n in neg_query_text], batch_first=True)\n",
    "        pos_query_text = pad_sequence([p for p in pos_query_text], batch_first=True)\n",
    "        neg_query_text, pos_query_text = pad_text(neg_query_text, pos_query_text)\n",
    "\n",
    "        # concatenating support/query text dataset\n",
    "        support_text = torch.cat([neg_support_text, pos_support_text], dim=0)\n",
    "        query_text = torch.cat([neg_query_text, pos_query_text], dim=0)\n",
    "        support_text, query_text = pad_text(support_text, query_text)\n",
    "\n",
    "        # make final data and label\n",
    "        if self.n_support:\n",
    "            data = torch.cat([support_text, query_text], dim=0)\n",
    "        else:\n",
    "            data = query_text\n",
    "        label = torch.cat([neg_support_label, pos_support_label, neg_query_label, pos_query_label], dim=0)\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e97b2228",
   "metadata": {},
   "outputs": [],
   "source": [
    "support = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b09877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = AmazonDataLoader(train_dataset, batch_size=64, n_support=support*2)\n",
    "dev_dataloader = AmazonDataLoader(dev_dataset, batch_size=64, n_support=support*2)\n",
    "test_dataloader = AmazonDataLoader(test_dataset, batch_size=64, n_support=support*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f6b30a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 149]) tensor(0.5000)\n",
      "torch.Size([64, 460]) tensor(0.5000)\n",
      "torch.Size([64, 254]) tensor(0.5000)\n",
      "torch.Size([64, 262]) tensor(0.5000)\n",
      "torch.Size([64, 1283]) tensor(0.5000)\n",
      "torch.Size([64, 1658]) tensor(0.5000)\n",
      "torch.Size([64, 613]) tensor(0.5000)\n",
      "torch.Size([64, 359]) tensor(0.5000)\n",
      "torch.Size([64, 530]) tensor(0.5000)\n",
      "torch.Size([64, 602]) tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    d, l = train_dataloader.get_batch()\n",
    "    print(d.shape, l.float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f653ad3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 327]) tensor(0.5000)\n",
      "torch.Size([55, 181]) tensor(0.5818)\n",
      "torch.Size([64, 198]) tensor(0.5000)\n",
      "torch.Size([46, 295]) tensor(0.6957)\n",
      "torch.Size([64, 197]) tensor(0.5000)\n",
      "torch.Size([64, 276]) tensor(0.5000)\n",
      "torch.Size([55, 186]) tensor(0.5818)\n",
      "torch.Size([64, 270]) tensor(0.5000)\n",
      "torch.Size([26, 130]) tensor(0.4615)\n",
      "torch.Size([64, 327]) tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    d, l = dev_dataloader.get_batch_test()\n",
    "    print(d.shape, l.float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ea86511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 743]) tensor(0.5000)\n",
      "torch.Size([64, 841]) tensor(0.5000)\n",
      "torch.Size([64, 1386]) tensor(0.5000)\n",
      "torch.Size([64, 706]) tensor(0.5000)\n",
      "torch.Size([64, 1026]) tensor(0.5000)\n",
      "torch.Size([64, 1126]) tensor(0.5000)\n",
      "torch.Size([64, 1116]) tensor(0.5000)\n",
      "torch.Size([64, 1333]) tensor(0.5000)\n",
      "torch.Size([64, 568]) tensor(0.5000)\n",
      "torch.Size([64, 570]) tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    d, l = test_dataloader.get_batch_test()\n",
    "    print(d.shape, l.float().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e25b2c",
   "metadata": {},
   "source": [
    "### 아마존 데이터셋에 대한 메타러닝 모델 클래스 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86929327",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotInduction(nn.Module):\n",
    "    def __init__(self, C, S, vocab_size, embed_size, hidden_size, d_a,\n",
    "                 iterations, outsize, weights=None):\n",
    "        super(FewShotInduction, self).__init__()\n",
    "        self.encoder = Encoder(C, S, vocab_size, embed_size, hidden_size, d_a, weights)\n",
    "        self.induction = Induction(C, S, 2 * hidden_size, iterations)\n",
    "        self.relation = Relation(C, 2 * hidden_size, outsize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        support_encoder, query_encoder = self.encoder(x)  # (k*c, 2*hidden_size)\n",
    "        # print('** support_encoder: {}'.format(support_encoder.shape))\n",
    "        # print('** query_encoder: {}'.format(query_encoder.shape))\n",
    "        class_vector = self.induction(support_encoder)\n",
    "        # print('** class_vector: {}'.format(class_vector.shape))\n",
    "        probs = self.relation(class_vector, query_encoder)\n",
    "        # print('** relation: {}'.format(probs.shape))\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16375bfd",
   "metadata": {},
   "source": [
    "### 아마존 데이터셋에 대한 메타러닝 모델 객체 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d0ada21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FewShotInduction(C=2,\n",
    "                         S=support,\n",
    "                         vocab_size=len(tokenizer),\n",
    "                         embed_size=300,\n",
    "                         hidden_size=128,\n",
    "                         d_a=64,\n",
    "                         iterations=3,\n",
    "                         outsize=100)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "028c86cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2288770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=float(1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67c7fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "\n",
    "class Criterion(_Loss):\n",
    "    def __init__(self, way=2, shot=5):\n",
    "        super(Criterion, self).__init__()\n",
    "        self.amount = way * shot\n",
    "\n",
    "    def forward(self, probs, target, return_pred_label=False):  # (Q,C) (Q)\n",
    "        target = target[self.amount:]\n",
    "        target_onehot = torch.zeros_like(probs)\n",
    "        #print('** sum of probs/target_onehot: {} {}'.format(probs.sum(), target_onehot.sum()))\n",
    "        target_onehot = target_onehot.scatter(1, target.reshape(-1, 1), 1)\n",
    "        loss = torch.mean((probs - target_onehot) ** 2)\n",
    "        pred = torch.argmax(probs, dim=1)\n",
    "        acc = torch.sum(target == pred).float() / target.shape[0]\n",
    "        #print('** acc: {}'.format(acc))\n",
    "\n",
    "        if return_pred_label:\n",
    "            return loss, acc, pred, target\n",
    "        else:\n",
    "            return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c398c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Criterion(way=2, shot=support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3871d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(episode):\n",
    "    model.train()\n",
    "    data, target = train_dataloader.get_batch()\n",
    "    if torch.cuda.is_available():\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    predict = model(data)\n",
    "    loss, acc = criterion(predict, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8db20a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dev(episode):\n",
    "    model.eval()\n",
    "    correct = 0.\n",
    "    count = 0.\n",
    "    for i in range(100):\n",
    "        data, target = dev_dataloader.get_batch_test()\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "            \n",
    "        predict = model(data)\n",
    "        _, acc = criterion(predict, target)\n",
    "        amount = len(target) - support * 2\n",
    "        correct += acc * amount\n",
    "        count += amount\n",
    "    acc = correct / count\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5cef811",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_interval = 100\n",
    "best_acc = -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe8f8bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                | 3/9999 [00:17<15:47:47,  5.69s/it, loss=tensor(0.4907, grad_fn=<MeanBackward0>)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m tbar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10000\u001b[39m))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m tbar:\n\u001b[1;32m----> 4\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m episode \u001b[38;5;241m%\u001b[39m dev_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      6\u001b[0m         acc \u001b[38;5;241m=\u001b[39m dev(episode)\n",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(episode)\u001b[0m\n\u001b[0;32m      9\u001b[0m predict \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[0;32m     10\u001b[0m loss, acc \u001b[38;5;241m=\u001b[39m criterion(predict, target)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mD:\\Study\\NotebookProjects\\hello-transformer\\venv\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Study\\NotebookProjects\\hello-transformer\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tbar = tqdm(range(1, 10000))\n",
    "for episode in tbar:\n",
    "    \n",
    "    loss = train(episode)\n",
    "    if episode % dev_interval == 0:\n",
    "        acc = dev(episode)\n",
    "        if acc > best_acc:\n",
    "            print('Better acc! Saving model! -> {:.4f}'.format(acc))\n",
    "            best_acc = acc\n",
    "    tbar.set_postfix(loss=loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44a2897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'fewshot_model_{support}.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2850445c",
   "metadata": {},
   "source": [
    "### 학습된 메타러닝 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c68249a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "support = 5\n",
    "criterion = Criterion(way=2, shot=support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d18232a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = FewShotInduction(C=2,\n",
    "                         S=support,\n",
    "                         vocab_size=len(tokenizer),\n",
    "                         embed_size=300,\n",
    "                         hidden_size=128,\n",
    "                         d_a=64,\n",
    "                         iterations=3,\n",
    "                         outsize=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82df0371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load(f'./fewshot_model_{support}.bin', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d18d8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0.\n",
    "    count = 0.\n",
    "    for i in range(100):\n",
    "        data, target = test_dataloader.get_batch_test()\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "            \n",
    "        predict = model(data)\n",
    "        _, acc = criterion(predict, target)\n",
    "        amount = len(target) - support * 2\n",
    "        correct += acc * amount\n",
    "        count += amount\n",
    "        \n",
    "    acc = correct / count\n",
    "    print('Test Acc: {}'.format(acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a6856ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m      8\u001b[0m target \u001b[38;5;241m=\u001b[39m target\n\u001b[1;32m----> 9\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m _, acc \u001b[38;5;241m=\u001b[39m criterion(predict, target)\n\u001b[0;32m     11\u001b[0m amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m-\u001b[39m support \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mD:\\Study\\NotebookProjects\\hello-transformer\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mFewShotInduction.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 105\u001b[0m     support_encoder, query_encoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (k*c, 2*hidden_size)\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;66;03m# print('** support_encoder: {}'.format(support_encoder.shape))\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# print('** query_encoder: {}'.format(query_encoder.shape))\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     class_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minduction(support_encoder)\n",
      "File \u001b[1;32mD:\\Study\\NotebookProjects\\hello-transformer\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     38\u001b[0m     h, c \u001b[38;5;241m=\u001b[39m hidden\n\u001b[0;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[1;32m---> 40\u001b[0m outputs, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbilstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch=k*c,seq_len,2*hidden)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(outputs)  \u001b[38;5;66;03m# (batch=k*c, 2*hidden)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# (c*s, 2*hidden_size), (c*q, 2*hidden_size)\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Study\\NotebookProjects\\hello-transformer\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Study\\NotebookProjects\\hello-transformer\\venv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:769\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    773\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c5889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
