{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d0151c",
   "metadata": {},
   "source": [
    "### GPT-2 모델 로딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea850286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (batch size x vocabulary size)\n",
    "            top_k > 0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p > 0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "        From: https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317\n",
    "    \"\"\"\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        # scatter sorted tensors to original indexing\n",
    "        indices_to_remove = sorted_indices_to_remove.scatter(dim=1, index=sorted_indices, src=sorted_indices_to_remove)\n",
    "        logits[indices_to_remove] = filter_value\n",
    "    return logits\n",
    "\n",
    "def sample_sequence(model, tokenizer, length, context, num_samples=1, temperature=1, top_k=0, top_p=0.0, repetition_penalty=1.0,\n",
    "                    is_xlnet=False, is_xlm_mlm=False, xlm_mask_token=None, xlm_lang=None, device='cpu'):\n",
    "    context = torch.tensor(context, dtype=torch.long, device=device)\n",
    "    context = context.unsqueeze(0).repeat(num_samples, 1)\n",
    "    generated = context\n",
    "    with torch.no_grad():\n",
    "        for idx in range(length):\n",
    "\n",
    "            inputs = {'input_ids': generated}\n",
    "            if is_xlnet: \n",
    "                input_ids = torch.cat((generated, torch.zeros((1, 1), dtype=torch.long, device=device)), dim=1)\n",
    "                perm_mask = torch.zeros((1, input_ids.shape[1], input_ids.shape[1]), dtype=torch.float, device=device)\n",
    "                perm_mask[:, :, -1] = 1.0  # Previous tokens don't see last token\n",
    "                target_mapping = torch.zeros((1, 1, input_ids.shape[1]), dtype=torch.float, device=device)\n",
    "                target_mapping[0, 0, -1] = 1.0  # predict last token\n",
    "                inputs = {'input_ids': input_ids, 'perm_mask': perm_mask, 'target_mapping': target_mapping}\n",
    "\n",
    "            if is_xlm_mlm and xlm_mask_token:\n",
    "                input_ids = torch.cat((generated, torch.full((1, 1), xlm_mask_token, dtype=torch.long, device=device)), dim=1)\n",
    "                inputs = {'input_ids': input_ids}\n",
    "\n",
    "            if xlm_lang is not None:\n",
    "                inputs[\"langs\"] = torch.tensor([xlm_lang] * inputs[\"input_ids\"].shape[1], device=device).view(1, -1)\n",
    "\n",
    "            outputs = model(**inputs)  # Note: we could also use 'past' with GPT-2/Transfo-XL/XLNet/CTRL (cached hidden-states)\n",
    "            next_token_logits = outputs[0][:, -1, :] / (temperature if temperature > 0 else 1.)\n",
    "\n",
    "            # repetition penalty from CTRL (https://arxiv.org/abs/1909.05858)\n",
    "            for i in range(num_samples):\n",
    "                for _ in set(generated[i].tolist()):\n",
    "                    next_token_logits[i, _] /= repetition_penalty\n",
    "                \n",
    "            filtered_logits = top_k_top_p_filtering(next_token_logits, top_k=top_k, top_p=top_p)\n",
    "            if temperature == 0: # greedy sampling:\n",
    "                next_token = torch.argmax(filtered_logits, dim=-1).unsqueeze(-1)\n",
    "            else:\n",
    "                next_token = torch.multinomial(F.softmax(filtered_logits, dim=-1), num_samples=1)\n",
    "            generated = torch.cat((generated, next_token), dim=1)\n",
    "    return generated\n",
    "\n",
    "\n",
    "def generate(model, tokenizer, raw_text, length=20, temperature=1.0, top_k=0.0, top_p=0.9, device=torch.device('cpu')): \n",
    "    context_tokens = tokenizer.encode(raw_text)\n",
    "    out = sample_sequence(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        context=context_tokens,\n",
    "        length=length,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        device=device,\n",
    "        is_xlnet=False,\n",
    "    )\n",
    "\n",
    "    out = out[0, len(context_tokens):].tolist()\n",
    "    text = tokenizer.decode(out, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93390ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "#from generation import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7626646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.device_count() > 0:\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5b207b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = int(10000)  # Hardcoded max length to avoid infinite loop\n",
    "length = 20\n",
    "\n",
    "temperature = 1.0\n",
    "top_k = 0.0\n",
    "top_p = 0.9\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    'gpt2': (GPT2LMHeadModel, GPT2Tokenizer),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b1578de",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4db42d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5e21952",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b36becb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'gpt2'\n",
    "model_name_or_path = 'gpt2'\n",
    "model_class, tokenizer_class = MODEL_CLASSES[model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "973a61ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel,\n",
       " transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class, tokenizer_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "735a63f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018792390823364258,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 50,
       "postfix": null,
       "prefix": "Downloading vocab.json",
       "rate": null,
       "total": 1042301,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf58febdfec7459aa22fa376ce525805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017894506454467773,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 50,
       "postfix": null,
       "prefix": "Downloading merges.txt",
       "rate": null,
       "total": 456318,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341765be8750402cbb5be8e9c69380bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018131017684936523,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 50,
       "postfix": null,
       "prefix": "Downloading config.json",
       "rate": null,
       "total": 665,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e937f4ef17641fe9f774164ef56d373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019499540328979492,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 50,
       "postfix": null,
       "prefix": "Downloading pytorch_model.bin",
       "rate": null,
       "total": 548118077,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869627446b89434e854771157f7d4273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/523M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(model_name_or_path)\n",
    "model = model_class.from_pretrained(model_name_or_path)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80b7d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b69e10",
   "metadata": {},
   "source": [
    "### generation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da60884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Whether the Ministry of Gender Equality & Family should remain in existence again surfaced as a hot button issue Friday\"\n",
    "text = generate(model, tokenizer, prompt, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71859622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Whether the Ministry of Gender Equality & Family should remain in existence again surfaced as a hot button issue Friday, the question that prompted further polarisation was \"suspicions.\"\\n\\nThe human rights'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt + text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37521eb6",
   "metadata": {},
   "source": [
    "### GPT2를 이용한 few shot 러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d95ff08",
   "metadata": {},
   "source": [
    "GPT2 few shot 러닝을 위한 프롬프트 텍스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ab324cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'play = played . sing = sang . view = viewed . act = acted . say = said . type = typed . note = noted . see = saw . clean = cleaned . tell = told . click ='"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd6bcda",
   "metadata": {},
   "source": [
    "few shot 러닝을 테스트할 동사 단어들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dca0f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = ['click', 'work', 'walk', 'run', 'jump']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fa60f9",
   "metadata": {},
   "source": [
    "few shot 러닝에 사용되는 서포트셋과 프롬프트의 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24b9480",
   "metadata": {},
   "source": [
    "```\n",
    "# 10개의 서포트셋\n",
    "play = played           # 1 shot\n",
    "sing = sang             # 2 shot\n",
    "view = viewed           # 3 shot\n",
    "act = acted             # 4 shot\n",
    "say = said              # 5 shot\n",
    "type = typed            # 6 shot\n",
    "note = noted            # 7 shot\n",
    "see = saw               # 8 shot\n",
    "clean = cleaned         # 9 shot\n",
    "tell = told             # 10 shot\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5d27d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plurals = []\n",
    "for verb in verbs:\n",
    "    prompt = f\"play = played . sing = sang . view = viewed . act = acted . say = said . type = typed . note = noted . see = saw . clean = cleaned . tell = told . {verb} =\"\n",
    "    plural = generate(model, tokenizer, prompt, device=device)\n",
    "    plural = plural.split(\".\")[0]\n",
    "    plurals.append(plural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cd898c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "click ->  clicked\n",
      "work ->  worked\n",
      "walk ->  walked\n",
      "run ->  run\n",
      "jump ->  jump\n"
     ]
    }
   ],
   "source": [
    "for v, p in zip(verbs, plurals):\n",
    "    print(f'{v} -> {p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cb26f9",
   "metadata": {},
   "source": [
    "마지막 jump 를 제외하면 단어의 원형과 과거형이 잘 매칭된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c952eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
